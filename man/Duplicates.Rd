% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Duplicates_class.R
\docType{class}
\name{Duplicates-class}
\alias{Duplicates-class}
\alias{Duplicates}
\title{Detect Duplicates}
\arguments{
\item{x}{a \code{partition_bundle} object defining the documents that will be
compared to detect duplicates}

\item{charRegex}{a regex defining the characters to keep}

\item{sAttribute}{the s-attribute providing the date}

\item{sample}{number of documents to define a subset of \code{partition_bundle} to
speed up character count}

\item{threshold}{numeric (0 < x < 1), the minimum similarity to qualify two documents as duplicates}

\item{mc}{logical, whether to use multicore}

\item{verbose}{logical, whether to be verbose}

\item{progress}{logical, whether to show progress bar}

\item{n}{The number of characters to use for shingling (\code{integer} value),
passed as argument \code{n} into \code{polmineR::ngrams()}. Defaults to 5, in
line with Kliche et al. 2014: 695.}

\item{Numeric/integer}{vector used for indexing \verb{$charCount} to select
the characters to keep. Defaults to 1:12, in line with Kliche et al.
2014: 695.}
}
\description{
Class for duplicate detection.
}
\details{
The class implements a procedure described by Fritz Kliche, Andre Blessing,
Urlich Heid and Jonathan Sonntag in the paper "The eIdentity Text
ExplorationWorkbench" presented at LREC 2014
(see \url{http://www.lrec-conf.org/proceedings/lrec2014/pdf/332_Paper.pdf}).

To detect duplicates, choices are made as follows:
(a) If two similar articles have been published on the same day, the shorter article will
be considered the duplicate; (b) if two similar articles were published on different days,
the article that appeared later will be considered the duplicate.

Different \code{partition_bundle}-objects can be passed into the \code{detectDuplicates}-method successively. The field
\code{duplicates} will be appended by the duplicates that are newly detected.
}
\section{Fields}{

\describe{
\item{\code{corpus}}{the CWB corpus the (last) \code{partition_bundle} used describes}

\item{\code{charRegex}}{regex defining the characters to keep}

\item{\code{charCount}}{count of the characters in the \code{partition_bundle}}

\item{\code{number}}{of days before and after a document was published}

\item{\code{pAttribute}}{the p-attribute used (defaults to "word")}

\item{\code{sAttribute}}{the s-attribute of the date of a text in the corpus}

\item{\code{sample}}{size of the sample of the \code{partition_bundle} that the character count is based on}

\item{\code{threshold}}{minimum similarity value to identify two texts as duplicates}

\item{\code{whatToCompare}}{a \code{simple_triplet_matrix} with the texts to be compared}

\item{\code{similarityMatrix}}{a \code{simple_triplet_matrix} with similarities of texts}

\item{\code{ngramDocumentMatrix}}{a matrix (inheriting from \code{TermDocumentMatrix}) with ngram counts in the documents of the \code{partition_bundle}}

\item{\code{datePrep}}{function to rework dates if not in the DD-MM-YYYY standard format}

\item{\code{annotation}}{a \code{data.table} with corpus positions}
}}

\section{Methods}{

\describe{
\item{\code{detectDuplicates(
  x,
  n = 5L,
  character_selection = 1:12,
  verbose = TRUE,
  mc = FALSE,
  progress = TRUE
)}}{Wrapper that implements the entire workflow for duplicate detection.}

\item{\code{encode(
  exec = FALSE,
  filenames = list(duplicate = tempfile(), original = tempfile())
)}}{Add structural attributes to CWB corpus based on the annotation data that has been generated
(data.table in field annotation).}

\item{\code{getWhatToCompare(
  x,
  reduce = TRUE,
  verbose = FALSE,
  progress = TRUE,
  mc = FALSE
)}}{Identify documents that will be compared (based on date of documents).}

\item{\code{initialize(
  charRegex = "[a-zA-Z]",
  pAttribute = "word",
  sAttribute = "text_date",
  datePrep = NULL,
  sample = 1000L,
  n = 1L,
  threshold = 0.9
)}}{Initialize object of class 'Duplicates'.}

\item{\code{makeAnnotation(sAttributeID)}}{Turn data.table with duplicates into file with corpus positions and annotation of duplicates,
generate cwb-s-encode command and execute it, if wanted.}

\item{\code{makeDuplicateDataTable(x, mc = FALSE, progress = TRUE, verbose = TRUE)}}{Turn similarities of documents into a data.table that identifies original document and duplicate.}
}}

\examples{
\dontrun{
foo <- partition_bundle(
  "KEYWORDS",
  def = list(text_newspaper="guardian"),
  var=list(text_id=sAttributes("KEYWORDS", "text_id")[1:500]),
  pAttribute=NULL
 )
doubled <- duplicates(foo)
}
}
